{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bb012ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5564a914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1506 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 256\n",
    "CHANNELS = 3\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        horizontal_flip=True,\n",
    "        rotation_range=10\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'dataset/train',\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse',\n",
    "     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78cb806b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "for image_batch, label_batch in train_generator:\n",
    "    print(image_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "349548d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 215 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen= ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        horizontal_flip=True,\n",
    "        rotation_range=10\n",
    ")\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    'dataset/val',\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse',\n",
    "     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "923beb0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 431 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        horizontal_flip=True,\n",
    "        rotation_range=10\n",
    ")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'dataset/test',\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=32,\n",
    "    class_mode='sparse',\n",
    "     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13ea87bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMAGE_SIZE, IMAGE_SIZE, CHANNELS)\n",
    "n_classes = 3\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.InputLayer(input_shape=input_shape),\n",
    "    layers.Conv2D(32, kernel_size = (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64,  kernel_size = (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(n_classes, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1be60e6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 30, 30, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 14, 14, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 12, 12, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 6, 6, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 64)          36928     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 2, 2, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 183,747\n",
      "Trainable params: 183,747\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13481fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "   metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d67ea56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47.0625"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1506/32 ##train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08e6f508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.71875"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "215/32  #validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8a0e69da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "47/47 [==============================] - 90s 2s/step - loss: 0.9503 - accuracy: 0.4294 - val_loss: 0.9145 - val_accuracy: 0.4531\n",
      "Epoch 2/20\n",
      "47/47 [==============================] - 70s 1s/step - loss: 0.8697 - accuracy: 0.5217 - val_loss: 0.7661 - val_accuracy: 0.7656\n",
      "Epoch 3/20\n",
      "47/47 [==============================] - 74s 2s/step - loss: 0.6031 - accuracy: 0.7483 - val_loss: 0.5455 - val_accuracy: 0.7812\n",
      "Epoch 4/20\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.4560 - accuracy: 0.8012 - val_loss: 0.3647 - val_accuracy: 0.8490\n",
      "Epoch 5/20\n",
      "47/47 [==============================] - 66s 1s/step - loss: 0.2965 - accuracy: 0.8935 - val_loss: 0.2908 - val_accuracy: 0.8802\n",
      "Epoch 6/20\n",
      "47/47 [==============================] - 67s 1s/step - loss: 0.3191 - accuracy: 0.8806 - val_loss: 0.3270 - val_accuracy: 0.8698\n",
      "Epoch 7/20\n",
      "47/47 [==============================] - 67s 1s/step - loss: 0.2059 - accuracy: 0.9199 - val_loss: 0.1679 - val_accuracy: 0.9323\n",
      "Epoch 8/20\n",
      "47/47 [==============================] - 67s 1s/step - loss: 0.1754 - accuracy: 0.9376 - val_loss: 0.2971 - val_accuracy: 0.8958\n",
      "Epoch 9/20\n",
      "47/47 [==============================] - 67s 1s/step - loss: 0.1976 - accuracy: 0.9193 - val_loss: 0.1787 - val_accuracy: 0.9323\n",
      "Epoch 10/20\n",
      "47/47 [==============================] - 68s 1s/step - loss: 0.1345 - accuracy: 0.9484 - val_loss: 0.1482 - val_accuracy: 0.9479\n",
      "Epoch 11/20\n",
      "47/47 [==============================] - 69s 1s/step - loss: 0.1353 - accuracy: 0.9498 - val_loss: 0.1753 - val_accuracy: 0.9375\n",
      "Epoch 12/20\n",
      "47/47 [==============================] - 69s 1s/step - loss: 0.1498 - accuracy: 0.9362 - val_loss: 0.2130 - val_accuracy: 0.9062\n",
      "Epoch 13/20\n",
      "47/47 [==============================] - 69s 2s/step - loss: 0.1061 - accuracy: 0.9600 - val_loss: 0.1165 - val_accuracy: 0.9427\n",
      "Epoch 14/20\n",
      "47/47 [==============================] - 79s 2s/step - loss: 0.1162 - accuracy: 0.9545 - val_loss: 0.1608 - val_accuracy: 0.9375\n",
      "Epoch 15/20\n",
      "47/47 [==============================] - 70s 1s/step - loss: 0.0846 - accuracy: 0.9695 - val_loss: 0.0746 - val_accuracy: 0.9635\n",
      "Epoch 16/20\n",
      "47/47 [==============================] - 71s 2s/step - loss: 0.0675 - accuracy: 0.9776 - val_loss: 0.1119 - val_accuracy: 0.9635\n",
      "Epoch 17/20\n",
      "47/47 [==============================] - 72s 2s/step - loss: 0.0597 - accuracy: 0.9776 - val_loss: 0.0591 - val_accuracy: 0.9740\n",
      "Epoch 18/20\n",
      "47/47 [==============================] - 74s 2s/step - loss: 0.0742 - accuracy: 0.9722 - val_loss: 0.0558 - val_accuracy: 0.9792\n",
      "Epoch 19/20\n",
      "47/47 [==============================] - 77s 2s/step - loss: 0.0744 - accuracy: 0.9708 - val_loss: 0.1438 - val_accuracy: 0.9427\n",
      "Epoch 20/20\n",
      "47/47 [==============================] - 76s 2s/step - loss: 0.0486 - accuracy: 0.9830 - val_loss: 0.1906 - val_accuracy: 0.9427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c8c14da530>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "   train_generator,\n",
    "   steps_per_epoch=47,\n",
    "    batch_size=32,\n",
    "    validation_data=validation_generator,\n",
    "     validation_steps=6,\n",
    "     verbose=1,\n",
    "      epochs=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "316301c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 9s 647ms/step - loss: 0.1429 - accuracy: 0.9420\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13681c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 7s 466ms/step - loss: 0.1646 - accuracy: 0.9397\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfb3098a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.16463066637516022, 0.9396751523017883]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1f6e1da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, img):\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(images[i])\n",
    "    img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "    predictions = model.predict(img_array)\n",
    "\n",
    "    predicted_class = class_names[np.argmax(predictions[0])]\n",
    "    confidence = round(100 * (np.max(predictions[0])), 2)\n",
    "    return predicted_class, confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4d3996eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../potatoes.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b52ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
